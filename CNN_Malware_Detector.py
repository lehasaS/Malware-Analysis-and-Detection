import torch
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from itertools import product
from data_loaders import get_image_data_loaders
import wandb
import pprint
from CNN_Models import *
wandb.login()

def build_optimizer(network, optimizer, learning_rate):
    if optimizer == "sgd":
        optimizer = optim.SGD(network.parameters(),
                              lr=learning_rate, momentum=0.9)
    elif optimizer == "adam":
        optimizer = optim.Adam(network.parameters(),
                               lr=learning_rate)
    return optimizer

def train(config=None):
        with wandb.init(config=config):
                config = wandb.config
                device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

                if(config.model_name == "Model One"):
                        network = MalCnnOne(config.dropout, config.image_size).to(device)
                else:
                        network = MalCnnTwo(config.dropout, config.image_size).to(device)
                
                print("Training for model: {}".format(network.CNN_name))
                
                criterion = nn.CrossEntropyLoss()
                train_loader, valid_loader, test_loader= get_image_data_loaders(config.image_size, config.batch_size)

                optimizer = build_optimizer(network, config.optimizer, config.learning_rate)

                valid_loss_min = np.Inf # track change in validation loss
                train_loss = 0.0
                train_corr = 0
                for epoch in range(config.epochs):
                        ###################
                        # train the model #
                        ###################
                        network.train()
                        for images, labels in train_loader:
                                images, labels = images.to(device), labels.to(device)
                                output = network(images)
                                
                                
                                loss = criterion(output, labels)
                                
                                train_loss += loss.item()*images.size(0)
                                predictions = torch.max(output.data, 1)[1]
                                batch_corr = (predictions == labels).sum()
                                train_corr += batch_corr.item()

                                optimizer.zero_grad()
                                loss.backward()
                                optimizer.step()

                        wandb.log({"loss":train_loss,"epoch":epoch})       
                                
                                
                        ######################    
                        # validate the model #
                        ######################
                        valid_loss = 0.0
                        val_corr=0
                        network.eval()
                        for images, labels in valid_loader:
                                images,labels = images.to(device),labels.to(device)
                                output = network(images)
                                loss = criterion(output, labels)
                                
                                valid_loss += loss.item()*images.size(0)

                                predict = torch.max(output.data, 1)[1]
                                val_batch_corr = (predict == labels).sum()
                                val_corr += val_batch_corr.item()
                
                        
                        train_loss = train_loss/len(train_loader.dataset)
                        valid_loss = valid_loss/len(valid_loader.dataset)

                        train_accuracy = train_corr * 100 / len(train_loader.dataset)
                        valid_accuracy = val_corr * 100 / len(valid_loader.dataset)
                        
                        # print training/validation statistics 
                        print("Epoch:{}/{} \t average training loss:{:.4f} average validation loss:{:.4f} \t average training acc.:{:.2f} \t average validation acc.:{:.2f}".format(epoch + 1, config.epochs,
                                                                                             train_loss,
                                                                                             valid_loss,
                                                                                             train_accuracy,
                                                                                             valid_accuracy))
                        
                        # save model if validation loss has decreased
                        if valid_loss <= valid_loss_min:
                                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(
                                valid_loss_min,
                                valid_loss))
                                torch.save(network.state_dict(), 'Mal_CNN_Detect_{}.pt'.format(config.sweep_id))
                                valid_loss_min = valid_loss

def main():
        sweep_config = {
        'method': 'grid'
        }

        metric = {
        'name': 'loss',
        'goal': 'minimize'   
        }
        sweep_config['metric'] = metric

        parameters_dict = {
        'optimizer': {
        'values': ['adam', 'sgd']
        },
        'batch_size': {
        'values': [32,64,128]
        },
        'image_size': {
        'values': [64,128,256]
        },
        'dropout': {
          'values': [0.1, 0.25, 0.5]
        },
        'epochs': {
                'value': 30
        },
        'model_name': {
                'values' : ["Model One", "Model Two"]
        }
        }
        sweep_config['parameters'] = parameters_dict
        
        sweep_id = wandb.sweep(sweep_config, project="CNN_Malware_Detection")

        parameters_dict.update({
                'sweep_id':{
                        'value': sweep_id
                },
                'learning_rate': {
                        # a flat distribution between 0 and 0.1
                        'distribution': 'uniform',
                        'min': 0,
                        'max': 0.01
                }
        })
        pprint.pprint(sweep_config)

        wandb.agent(sweep_id, train)
        wandb.finish()

if __name__=="__main__":
        main()