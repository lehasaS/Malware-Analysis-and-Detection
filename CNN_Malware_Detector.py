import torch
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from itertools import product
from data_loaders import get_image_data_loaders
import wandb
import pprint
wandb.login()

class MalCnn(nn.Module):
    def __init__(self, dropout, image_size):
        super(MalCnn, self).__init__()
        self.dropout=dropout
        self.image_size=image_size
        #Convolutions
        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)
        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)
        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)

        #Pooling layer
        self.pool = nn.MaxPool2d(2, 2)
        
        #Fully connected layers
        self.fc1 = nn.Linear(self.image_size*self.image_size,512)
        self.fc2 = nn.Linear(512, 256)
        self.fc3 = nn.Linear(256, 2)
        
        self.dropout = nn.Dropout(self.dropout)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = self.pool(F.relu(self.conv3(x)))
        x = x.view(-1,self.image_size*self.image_size)
        
        x = self.dropout(F.relu(self.fc1(x)))

        x=self.dropout(F.relu(self.fc2(x)))

        x = F.log_softmax(self.fc3(x),dim=1)

        return x

def build_optimizer(network, optimizer, learning_rate):
    if optimizer == "sgd":
        optimizer = optim.SGD(network.parameters(),
                              lr=learning_rate, momentum=0.9)
    elif optimizer == "adam":
        optimizer = optim.Adam(network.parameters(),
                               lr=learning_rate)
    return optimizer

def train(config=None):
        with wandb.init(config=config):
                config = wandb.config
                device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
                network = MalCnn(config.dropout, config.image_size).to(device)
                criterion = nn.CrossEntropyLoss()
                train_loader, valid_loader, test_loader= get_image_data_loaders(config.image_size, config.batch_size)

                optimizer = build_optimizer(network, config.optimizer, config.learning_rate)

                valid_loss_min = np.Inf # track change in validation loss
                train_loss = 0.0
                training_correct = 0
                for epoch in range(config.epochs):
                        ###################
                        # train the model #
                        ###################
                        network.train()
                        for images, labels in train_loader:
                                images, labels = images.to(device), labels.to(device)
                                optimizer.zero_grad()
                                output = network(images)
                                
                                
                                loss = criterion(output, labels)
                                loss.backward()
                                optimizer.step()
                                train_loss += loss.item()*images.size(0)
                                scores, predictions = torch.max(output.data, 1)
                                training_correct+= (predictions == labels).sum().item() 

                        wandb.log({"loss":train_loss,"epoch":epoch})       
                                
                                
                        ######################    
                        # validate the model #
                        ######################
                        valid_loss = 0.0
                        valid_correct=0
                        network.eval()
                        for images, labels in valid_loader:
                                images,labels = images.to(device),labels.to(device)
                                output = network(images)
                                loss = criterion(output, labels)
                                
                                valid_loss += loss.item()*images.size(0)
                                scores, predictions = torch.max(output.data,1)
                                valid_correct+=(predictions == labels).sum().item()
                
                        
                        train_loss = train_loss/len(train_loader.dataset)
                        train_accuracy = training_correct / len(train_loader.dataset)*100
                        valid_loss = valid_loss/len(valid_loader.dataset)
                        valid_accuracy = valid_correct / len(valid_loader.dataset) * 100
                        
                        # print training/validation statistics 
                        print("Epoch:{}/{} \t average training loss:{:.4f} average validation loss:{:.4f} \t average training acc.:{:.2f} %  average validation acc.:{:.2f} %".format(epoch + 1, config.epochs,
                                                                                             train_loss,
                                                                                             valid_loss,
                                                                                             train_accuracy,
                                                                                            valid_accuracy))
                        
                        # save model if validation loss has decreased
                        if valid_loss <= valid_loss_min:
                                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(
                                valid_loss_min,
                                valid_loss))
                                torch.save(network.state_dict(), 'Mal_CNN_Detect.pt')
                                valid_loss_min = valid_loss

def main():
        sweep_config = {
        'method': 'random'
        }

        metric = {
        'name': 'loss',
        'goal': 'minimize'   
        }
        sweep_config['metric'] = metric

        parameters_dict = {
        'optimizer': {
        'values': ['adam', 'sgd']
        },
        'batch_size': {
        'values': [32,64,128]
        },
        'image_size': {
        'values': [64,128,256]
        },
        'dropout': {
          'values': [0.1, 0.3, 0.5]
        },
        'epochs': {
                'value': 30
        },
        'learning_rate': {
                # a flat distribution between 0 and 0.1
                'distribution': 'uniform',
                'min': 0,
                'max': 0.1
        }
        }
        sweep_config['parameters'] = parameters_dict
        pprint.pprint(sweep_config)

        sweep_id = wandb.sweep(sweep_config, project="CNN_Malware_Detection")

        wandb.agent(sweep_id, train)
        wandb.finish()

if __name__=="__main__":
        main()